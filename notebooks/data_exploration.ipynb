{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to explore the data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import sys\n",
    "from transformers import AutoTokenizer\n",
    "sys.path.append('/mnt/qb/work/eickhoff/esx208/arithmetic-lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scratch_local/esx208-817388/ir_mech_interp/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tok = AutoTokenizer.from_pretrained('EleutherAI/pythia-12b-deduped-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 751, 14168]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.encode('I like math', add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXTokenizerFast(name_or_path='EleutherAI/pythia-12b-deduped-v0', vocab_size=50254, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<|padding|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50254: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50255: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50256: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50257: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50258: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50259: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50260: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50261: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50262: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50263: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50264: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50265: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50266: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50267: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50268: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50269: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50270: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50271: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50272: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50273: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50274: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50275: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50276: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([209])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_test = pickle.load(open('/mnt/qb/work/eickhoff/esx208/arithmetic-lm/data_test/EleutherAI/pythia-12b-deduped-v0/intervention_1_shots_max_20_arabic_further_templates.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 740,  559,  374,  559,  495,  426, 1458,   15,  374,  559,  721,  559,\n",
       "          721,  426]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].base_string_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 + 2 + 3 = 15. 2 + 6 + 6 ='"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(data_1_test[0].base_string_tok_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1638]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].res_alt_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1638]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].res_base_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 10'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].pred_alt_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 10'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<interventions.Intervention at 0x7f1048800b20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].pred_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 + 2 + 3 = 15. 2 + 6 + 6 =\n",
      "5 + 4 + 2 = 11. 8 + 6 + 5 =\n",
      "5 + 6 + 3 = 14. 4 + 4 + 11 =\n",
      "2 + 6 + 5 = 13. 2 + 6 + 6 =\n",
      "6 + 2 + 5 = 13. 11 + 3 + 2 =\n",
      "5 + 7 + 6 = 18. 11 + 2 + 6 =\n",
      "2 + 2 + 7 = 11. 3 + 2 + 6 =\n",
      "4 + 4 + 4 = 12. 8 + 7 + 4 =\n",
      "4 + 5 + 8 = 17. 6 + 7 + 5 =\n",
      "The result of 9 + 4 + 6 = 19. The result of 8 + 4 + 3 =\n",
      "The result of 7 + 5 + 3 = 15. The result of 2 + 7 + 6 =\n",
      "The result of 7 + 4 + 4 = 15. The result of 4 + 2 + 3 =\n",
      "The result of 5 + 12 + 2 = 19. The result of 2 + 7 + 2 =\n",
      "The result of 5 + 6 + 3 = 14. The result of 6 + 10 + 2 =\n",
      "The result of 7 + 3 + 5 = 15. The result of 3 + 4 + 3 =\n",
      "The result of 2 + 13 + 3 = 18. The result of 5 + 7 + 5 =\n",
      "The result of 5 + 7 + 5 = 17. The result of 9 + 6 + 2 =\n",
      "The result of 5 + 5 + 6 = 16. The result of 3 + 4 + 9 =\n",
      "The result of 7 + 6 + 2 = 15. The result of 3 + 3 + 3 =\n",
      "The result of 2 + 10 + 6 = 18. The result of 4 + 3 + 3 =\n",
      "The result of 5 + 7 + 3 = 15. The result of 10 + 2 + 6 =\n",
      "The result of 9 + 3 + 3 = 15. The result of 4 + 12 + 2 =\n",
      "The result of 4 + 8 + 7 = 19. The result of 8 + 2 + 3 =\n",
      "The result of 4 + 10 + 3 = 17. The result of 10 + 3 + 4 =\n",
      "The result of 3 + 5 + 5 = 13. The result of 5 + 3 + 4 =\n",
      "The result of 3 + 5 + 6 = 14. The result of 10 + 4 + 2 =\n",
      "The result of 4 + 4 + 4 = 12. The result of 11 + 6 + 2 =\n",
      "The result of 7 + 2 + 2 = 11. The result of 2 + 9 + 7 =\n",
      "The result of 3 + 4 + 4 = 11. The result of 3 + 2 + 10 =\n",
      "The result of 3 + 6 + 4 = 13. The result of 9 + 7 + 2 =\n",
      "The result of 4 + 7 + 3 = 14. The result of 3 + 2 + 9 =\n",
      "The result of 5 + 4 + 9 = 18. The result of 2 + 9 + 2 =\n",
      "The result of 3 + 5 + 5 = 13. The result of 3 + 3 + 2 =\n",
      "The result of 3 + 2 + 6 = 11. The result of 8 + 2 + 8 =\n",
      "The result of 18 minus 5 minus 2 is 11. The result of 16 minus 10 minus 5 is\n",
      "The result of 19 minus 6 minus 7 is 6. The result of 12 minus 2 minus 6 is\n",
      "The result of 18 minus 4 minus 13 is 1. The result of 20 minus 15 minus 2 is\n",
      "The result of 15 minus 12 minus 2 is 1. The result of 20 minus 5 minus 10 is\n",
      "The result of 19 minus 10 minus 8 is 1. The result of 11 minus 6 minus 2 is\n",
      "The result of 2 * 3 * 2 = 12. The result of 2 * 2 * 3 =\n",
      "The result of 4 * 2 * 2 = 16. The result of 2 * 2 * 3 =\n",
      "The result of 4 * 2 * 2 = 16. The result of 3 * 2 * 3 =\n",
      "The result of 2 * 2 * 3 = 12. The result of 3 * 2 * 2 =\n",
      "The result of 2 * 2 * 2 = 8. The result of 2 * 3 * 2 =\n",
      "The result of 2 * 2 * 3 = 12. The result of 3 * 3 * 2 =\n",
      "The result of 3 * 2 * 2 = 12. The result of 3 * 2 * 3 =\n",
      "The result of 3 * 3 * 2 = 18. The result of 2 * 3 * 2 =\n",
      "The result of 2 * 3 * 3 = 18. The result of 4 * 2 * 2 =\n",
      "The result of 2 * 2 * 3 = 12. The result of 3 * 3 * 2 =\n",
      "The result of 2 * 2 * 3 = 12. The result of 2 * 2 * 4 =\n",
      "The result of 3 * 3 * 2 = 18. The result of 2 * 3 * 3 =\n",
      "The result of 2 * 2 * 4 = 16. The result of 2 * 3 * 2 =\n",
      "The result of 2 * 2 * 3 = 12. The result of 3 * 3 * 2 =\n",
      "The result of 3 * 3 * 2 = 18. The result of 2 * 2 * 4 =\n",
      "The result of 3 * 2 * 3 = 18. The result of 3 * 3 * 2 =\n",
      "The result of 3 * 3 * 2 = 18. The result of 4 * 2 * 2 =\n",
      "The result of 2 * 3 * 2 = 12. The result of 2 * 2 * 3 =\n",
      "The result of 3 * 3 * 2 = 18. The result of 2 * 4 * 2 =\n",
      "The result of 2 * 2 * 3 = 12. The result of 3 * 2 * 3 =\n",
      "The result of 4 * 2 * 2 = 16. The result of 2 * 2 * 3 =\n",
      "The result of 2 * 2 * 4 = 16. The result of 2 * 3 * 2 =\n",
      "The result of 3 * 3 * 2 = 18. The result of 3 * 3 * 2 =\n",
      "The result of 2 * 3 * 3 = 18. The result of 4 * 2 * 2 =\n",
      "The result of 3 * 2 * 3 = 18. The result of 2 * 3 * 3 =\n",
      "The result of 2 * 3 * 2 = 12. The result of 2 * 3 * 2 =\n",
      "The result of 2 times 2 times 2 = 8. The result of 3 times 3 times 2 =\n",
      "The result of 2 times 3 times 3 = 18. The result of 3 times 3 times 2 =\n",
      "The result of 2 times 4 times 2 = 16. The result of 3 times 3 times 2 =\n",
      "The result of 4 times 2 times 2 = 16. The result of 2 times 3 times 3 =\n",
      "The result of 3 times 3 times 2 = 18. The result of 2 times 4 times 2 =\n",
      "The result of 2 times 3 times 2 = 12. The result of 2 times 2 times 2 =\n",
      "The result of 2 times 3 times 2 = 12. The result of 3 times 3 times 2 =\n",
      "The result of 2 times 4 times 2 = 16. The result of 3 times 2 times 2 =\n",
      "The result of 4 times 2 times 2 = 16. The result of 2 times 3 times 2 =\n",
      "The result of 3 times 2 times 3 = 18. The result of 3 times 3 times 2 =\n",
      "The result of 3 times 2 times 2 = 12. The result of 3 times 2 times 3 =\n",
      "The result of 2 times 4 times 2 = 16. The result of 2 times 4 times 2 =\n",
      "The result of 3 times 3 times 2 = 18. The result of 2 times 3 times 3 =\n",
      "The result of 2 times 2 times 4 = 16. The result of 2 times 3 times 2 =\n",
      "The result of 2 times 4 times 2 = 16. The result of 2 times 2 times 2 =\n",
      "The result of 4 times 2 times 2 = 16. The result of 3 times 2 times 3 =\n",
      "The result of 3 times 2 times 3 = 18. The result of 2 times 2 times 3 =\n",
      "The result of 4 times 2 times 2 = 16. The result of 2 times 2 times 2 =\n",
      "The result of 2 times 3 times 3 = 18. The result of 2 times 2 times 3 =\n",
      "The result of 2 times 2 times 2 = 8. The result of 3 times 2 times 3 =\n",
      "The result of 2 times 4 times 2 = 16. The result of 2 times 2 times 3 =\n",
      "The result of 2 times 4 times 2 = 16. The result of 2 times 2 times 2 =\n",
      "The result of 2 times 2 times 4 = 16. The result of 3 times 2 times 3 =\n",
      "2 * 4 * 2 = 16. 3 * 3 * 2 =\n",
      "2 * 2 * 4 = 16. 2 * 3 * 3 =\n",
      "3 * 3 * 2 = 18. 2 * 3 * 3 =\n",
      "2 * 2 * 3 = 12. 2 * 3 * 3 =\n",
      "3 * 2 * 3 = 18. 3 * 3 * 2 =\n",
      "3 * 3 * 2 = 18. 3 * 3 * 2 =\n",
      "2 * 2 * 3 = 12. 2 * 3 * 3 =\n",
      "The result of ( 15 - 14 ) * 9 = 9. The result of ( 15 - 14 ) * 12 =\n",
      "The result of ( 8 - 7 ) * 8 = 8. The result of ( 19 - 18 ) * 2 =\n",
      "The result of ( 18 - 17 ) * 6 = 6. The result of ( 6 - 5 ) * 3 =\n",
      "The result of ( 3 - 2 ) * 16 = 16. The result of ( 20 - 19 ) * 16 =\n",
      "The result of ( 20 - 15 ) * 2 = 10. The result of ( 18 - 14 ) * 4 =\n",
      "The result of ( 20 - 19 ) * 6 = 6. The result of ( 6 - 5 ) * 14 =\n",
      "The result of ( 9 - 8 ) * 9 = 9. The result of ( 13 - 12 ) * 2 =\n",
      "The result of ( 8 - 6 ) * 3 = 6. The result of ( 8 - 7 ) * 6 =\n",
      "The result of ( 16 - 14 ) * 7 = 14. The result of ( 3 - 2 ) * 18 =\n",
      "The result of ( 16 - 15 ) * 4 = 4. The result of ( 10 - 9 ) * 17 =\n",
      "The result of ( 11 - 10 ) * 15 = 15. The result of ( 11 - 10 ) * 14 =\n",
      "The result of ( 12 - 10 ) * 2 = 4. The result of ( 11 - 10 ) * 16 =\n",
      "The result of ( 15 - 13 ) * 2 = 4. The result of ( 9 - 6 ) * 2 =\n"
     ]
    }
   ],
   "source": [
    "for item in data_1_test:\n",
    "    print(tok.decode(item.base_string_tok_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[740, 559, 374, 559, 495, 426, 1458, 15, 374, 559, 721, 559, 721, 426]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].base_string_tok_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 + 6 + 6 ='"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].base_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 + 6 + 6 ='"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].alt_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].extended_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_test[0].res_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 + 6 + 6 ='"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].alt_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[209, 209, 209, 209, 209, 209, 209, 0, 374, 559, 721, 559, 721, 426]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokedata_1_test[0].alt_string_tok_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10 + 2 + 3 = 15. '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].few_shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].few_shots_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].res_base_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1_test[0].res_alt_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_test[0].res_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_test[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Intervention in module interventions object:\n",
      "\n",
      "class Intervention(builtins.object)\n",
      " |  Intervention(tokenizer, template_type, base_string: str, alt_string: str, equation: str, n_vars, is_opt, is_bloom, is_mistral, is_persimmon, representation, extended_templates, few_shots='', few_shots_t2=None, multitoken=False, device='cpu')\n",
      " |  \n",
      " |  Wrapper for all the possible interventions\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tokenizer, template_type, base_string: str, alt_string: str, equation: str, n_vars, is_opt, is_bloom, is_mistral, is_persimmon, representation, extended_templates, few_shots='', few_shots_t2=None, multitoken=False, device='cpu')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_position_of_tokens(self, operands_base, operands_alt, operator_word, no_space_before_op1=False)\n",
      " |  \n",
      " |  set_position_of_tokens_int11(self, e1, e2)\n",
      " |  \n",
      " |  set_position_of_tokens_lama(self, subj_base, subj_alt, no_space_before_sub=False)\n",
      " |  \n",
      " |  set_position_of_tokens_three_operands(self, operands_base, operands_alt)\n",
      " |  \n",
      " |  set_predicted_alt_result(self, pred_alt_string, pred_res_alt_tok)\n",
      " |  \n",
      " |  set_result(self, res)\n",
      " |  \n",
      " |  set_results(self, res_base, res_alt)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  index_last_occurrence(lst, item)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data_1_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error while attempting to unpickle Tokenizer: data did not match any variant of untagged enum ModelWrapper at line 1 column 1559948",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_1 \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mnt/qb/work/eickhoff/esx208/arithmetic-lm/data/intervention_1_shots_max_20_arabic_further_templates.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mException\u001b[0m: Error while attempting to unpickle Tokenizer: data did not match any variant of untagged enum ModelWrapper at line 1 column 1559948"
     ]
    }
   ],
   "source": [
    "data_1 = pickle.load(open('/mnt/qb/work/eickhoff/esx208/arithmetic-lm/data/intervention_1_shots_max_20_arabic_further_templates.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error while attempting to unpickle Tokenizer: data did not match any variant of untagged enum ModelWrapper at line 1 column 1559948",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mnt/qb/work/eickhoff/esx208/arithmetic-lm/data/intervention_1_shots_max_20_words_further_templates.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/scratch_local/esx208-814654/arithmetic_lm/lib/python3.11/site-packages/torch/serialization.py:815\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/scratch_local/esx208-814654/arithmetic_lm/lib/python3.11/site-packages/torch/serialization.py:1033\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1029\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1030\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1033\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Error while attempting to unpickle Tokenizer: data did not match any variant of untagged enum ModelWrapper at line 1 column 1559948"
     ]
    }
   ],
   "source": [
    "data_2 = torch.load('/mnt/qb/work/eickhoff/esx208/arithmetic-lm/data/intervention_1_shots_max_20_words_further_templates.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
